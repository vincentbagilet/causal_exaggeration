The credibility revolution has made causal inference methods ubiquitous in economics, yet it has developed within a discipline that rewards statistically significant findings. I show that these two forces interact in ways that reduce the reliability of published estimates: while causal identification strategies alleviate bias from confounders, they reduce statistical power and can generate another type of bias---exaggeration---when combined with selection on significance. I characterize this confoundingâ€“exaggeration trade-off theoretically and via realistic Monte Carlo simulations, document its prevalence in the literature, and propose practical solutions, including a tool to identify the variation actually driving identification.

%The credibility revolution in economics has made causal inference methods ubiquitous. Simultaneously, an increasing amount of evidence highlights that the literature strongly favors statistically significant results. I show that these two phenomena interact in a way that can substantially worsen the reliability of published estimates: while causal identification strategies alleviate bias caused by confounders, they reduce statistical power and can create another type of bias---exaggeration--- when combined with selection on significance. I characterize this confounding-exaggeration trade-off theoretically and using realistic Monte Carlo simulations replicating prevailing identification strategies and document its prevalence in the literature. I then present concrete solutions to address this issue when implementing a study, and in particular develop a tool to identify the variation actually used for identification. 

%Previous version
% The credibility revolution in economics has made causal inference methods ubiquitous. Simultaneously, an increasing amount of evidence highlights that the literature strongly favors statistically significant results. I show that these two phenomena interact in a way that can substantially worsen the reliability of published estimates: while causal identification strategies alleviate bias caused by confounders, they reduce statistical power and can create another type of bias---exaggeration--- when combined with selection on significance. This is consequential as estimates are routinely turned into decision-making parameters for policy makers conducting cost-benefit analyses. I characterize this confounding-exaggeration trade-off theoretically and using realistic Monte Carlo simulations replicating prevailing identification strategies and document its prevalence in the literature. I then discuss potential avenues to address this issue.